---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm an AI4SE researcher building trustworthy, efficient, and sustainable software using AI. I currently work as a postdoctoral [KTP Associate](https://www.ktp-uk.org/) with both the [University of Leeds](https://www.leeds.ac.uk/) and [TurinTech AI](https://www.turintech.ai/), focusing on compiler- and LLM-based code optimisation.
At the University of Leeds, I am a member of the [Intelligent Systems Software Lab (ISSL)](https://issl-uk.com/) and the [Distributed Systems and Services (DSS)](https://distributed-systems.leeds.ac.uk/) research group, supervised by [Prof Jie Xu](https://eps.leeds.ac.uk/computing/staff/331/professor-jie-xu) and [Prof Zheng Wang](https://zwang4.github.io/). 
At TurinTech AI, I'm a member of the Data Science team led by [Dr Fan Wu](https://scholar.google.com/citations?user=p8z2_usAAAAJ&hl=en) and [Dr Paul Brookes](https://www.linkedin.com/in/paul-brookes-125288b2/).

I completed my PhD in Dec 2024 in the [Department of Computer Science](https://www.lboro.ac.uk/departments/compsci/) at [Loughborough University](https://www.lboro.ac.uk/), supervised by [Dr Tao Chen](https://scholar.google.co.uk/citations?user=K4teyvoAAAAJ&hl=en) in the [<kbd>IDEAS Laboratory</kbd>](https://ideas-labo.github.io/) (Intelligent Dependability Engineering for Adaptive Software Laboratory). My PhD thesis received the [SPEC Kaivalya Dixit Distinguished Dissertation Award 2024](https://research.spec.org/awards/), a prominent award in computer benchmarking, performance evaluation, and experimental system analysis.

## Research Focus
I work across different AI-powered techniques for software performance engineering, from foundational machine learning models to cutting‑edge GenAI systems.

- **Doctoral research — Software configuration performance engineering**
  - Developed [ML/DL approaches](https://dl.acm.org/doi/full/10.1145/3702986) that learn the 
    high‑dimensional configuration options to 
    predict and optimise performance without 
    exhaustive benchmarking, addressing critial 
    challenges such as [feature sparsity](https://ieeexplore.ieee.org/abstract/document/10744216), [rugged performance spaces](https://ieeexplore.ieee.org/abstract/document/10832565), and [cross‑environment drift](https://dl.acm.org/doi/abs/10.1145/3643743) (versions/hardware/workloads).
  - **Why it matters**: This 
    enables earlier performance issue detection, 
    software adaptibility and autoscaling, and 
    faster product evolution with far fewer 
    measurements.

- **Current research — GenAI for industrial code performance optimisation**
  - Lead work on [search-based multi‑LLM optimisation](https://arxiv.org/abs/2501.01277) and [meta‑prompting](https://arxiv.org/abs/2508.01443) for robust code scoring/optimization, combined with [ensembling](https://arxiv.org/abs/2503.13505) and compiler techniques; implemented in commercial platforms via the collaboration with [TurinTech AI](https://www.turintech.ai/) and evaluated on real production workloads.
  - **Why it matters**: Our methods deliver verifiable speedups and cost reductions on production codebases while making GenAI systems more reliable and auditable in practice.

- **Ongoing interests — AI-driven performance engineering, AI4SE, SE4AI**
  - LLM performance modeling (hybrid models + online adaptive tuning), performance‑aware GenAI systems (dynamic prompt engineering + configuration tuning), trustworthy GenAI (RLHF + uncertainty verification), and industry standards/tooling (benchmarks, profiling + static analysis validation, CI/CD integration).
  - **Why it matters**: These directions make GenAI 
  systems predictable and safe in real-world 
  workloads, enabling reproducible evaluation, 
  faster industrial adoption, and lower compute 
  and carbon footprints.

If you’re interested in collaboration, please feel free to reach out!

## News
>
>* **July/2025:** I am honored to be selected as a **Shadow Program Committee Member** for the *IEEE/ACM International Conference on Software Engineering* [(ICSE 2026)](https://conf.researchr.org/home/icse-2026).
>
>
>* **June/2025:** Our paper '[Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning](https://arxiv.org/abs/2507.08730)' has been accepted by the *IEEE/ACM International Conference on Software Engineering* [(ICSE)](https://conf.researchr.org/home/icse-2026) as a research paper in the first round with acceptance rate 9.29% (60/646).
>
>
>* **June/2025:** Our paper '[Learning Software Bug Reports: A Systematic Literature Review](https://dl.acm.org/doi/abs/10.1145/3750040)' has been accepted by the *ACM Transactions on Software Engineering and Methodology
[(TOSEM)](https://dl.acm.org/toc/tosem/justaccepted) as a journal paper.
>
>
>* **January/2025:** I am honored to be awarded the [SPEC Kaivalya Dixit Distinguished Dissertation Award 2024](https://research.spec.org/news/2025-01-31-00-00-winner-of-spec-kaivalya-dixit-distinguished-dissertation-award-2024/), 
which is a prominent award in the domain of in computer benchmarking, performance evaluation, and experimental system analysis. 
Grateful to @[spec_perf](https://x.com/spec_perf) for recognizing our contributions to performance engineering! Thank you @[tao_chen_ideas](https://x.com/tao_chen_ideas) and @[PooyanJamshidi](https://x.com/PooyanJamshidi) for your unwavering support!
>
> 
>* **November/2024:** Our paper '[Accuracy Can Lie: On the Impact of Surrogate Model in Configuration Tuning](https://ieeexplore.ieee.org/abstract/document/10832565)' has been accepted by the *IEEE Transactions on Software Engineering* [(TSE)](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=32) as a journal paper.
>
> 
>* **October/2024:** Our paper '[Dividable Configuration Performance Learning](https://arxiv.org/abs/2409.07629)' has been accepted by the *IEEE Transactions on Software Engineering* [(TSE)](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=32) as a journal paper.
>
> 
>* **September/2024:** I am selected as a **Junior Program Committee member** for the *ACM/IEEE International Conference on Mining Software Repositories* [(MSR 2025)](https://conf.researchr.org/home/msr-2025).
>
> 
>* **August/2024:** Our paper '[Deep Configuration Performance Learning: A Systematic Survey and Taxonomy](https://arxiv.org/abs/2403.03322)' has been accepted by the *ACM Transactions on Software Engineering and Methodology* [(TOSEM)](https://dl.acm.org/journal/tosem) as a survey paper.
>
> 
>* **July/2024:** The team I led received the **SSBSE'24 Challenge Track award** for the paper '[GreenStableYolo: Optimizing Inference Time and Image Quality of Text-to-Image Generation](https://arxiv.org/abs/2407.14982)', thanks and 
congratulations to all the authors!  
>
> 
>* **May/2024:** Our paper '[GreenStableYolo: Optimizing Inference Time and Image Quality of Text-to-Image Generation](https://arxiv.org/abs/2407.14982)' has been accepted by the *Symposium on Search-Based Software Engineering* [(SSBSE 2024)](https://conf.researchr.org/track/ssbse-2024/ssbse-2024-challenge) as a challenge track paper. 
>
> 
>* **January/2024:** Our paper '[Predicting Configuration Performance in Multiple Environments with Sequential Meta-Leaning](https://arxiv.org/abs/2402.03183)' has been accepted by the *ACM International Conference on the Foundations of Software Engineering* [(FSE 2024)](https://conf.researchr.org/home/fse-2024) as a research paper with acceptance rate 11.6% (56 out of 483). 
>
>
>* **May/2023:** Our paper '[Predicting Software Performance with Divide-and-Learn](https://arxiv.org/pdf/2306.06651)' has been accepted by the *ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering* [(ESEC/FSE 2023)](https://2023.esec-fse.org/) as a research paper with two strong accepts and no revision requested; acceptance rate 12.7% (60/473).
>
>* **May/2022:** Our paper '[Does Configuration Encoding Matter in Learning Software Performance? An Empirical Study on Encoding Schemes](https://arxiv.org/abs/2203.15988)' has been accepted by the *19th International Conference on Mining Software Repositories* [(MSR 2022)](https://conf.researchr.org/details/msr-2022/msr-2022-technical-papers/1/Does-Configuration-Encoding-Matter-in-Learning-Software-Performance-An-Empirical-Stu) as a technical paper, with an acceptance rate of 34% (45/138).
>
>

## Selected Publications
* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">ICSE</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-A</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CORE-A*</span> Z. Xiang, <b>J. Gong</b>, and T. Chen, <a href="https://arxiv.org/abs/2507.08730">Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning</a>, The IEEE/ACM International Conference on Software Engineering <a href="https://conf.researchr.org/home/icse-2026">(ICSE)</a>, 2026, 13 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">TOSEM</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-A</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">JCR-Q1</span> G. Long, <b>J. Gong</b>, Hui Fang, and T. Chen, <a href="https://dl.acm.org/doi/abs/10.1145/3750040">Learning Software Bug Reports: A Systematic Literature Review</a>, The ACM Transactions on Software Engineering and Methodology <a href="https://dl.acm.org/toc/tosem/justaccepted">(TOSEM)</a>, 2025, 47 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">TSE</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-A</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">JCR-Q1</span> P. Chen, <b>J. Gong</b>, and T. Chen, <a href="https://ieeexplore.ieee.org/abstract/document/10832565">Accuracy Can Lie: On the Impact of Surrogate Model in Configuration Tuning</a>, The IEEE Transactions on Software Engineering <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=32">(TSE)</a>, 2024, 33 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">TSE</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-A</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">JCR-Q1</span> <b>J. Gong</b>, T. Chen, and R. Bahsoon, <a href="https://arxiv.org/abs/2409.07629">Dividable Configuration Performance Learning</a>, The IEEE Transactions on Software Engineering <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=32">(TSE)</a>, 2024, 29 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">TOSEM</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-A</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">JCR-Q1</span> <b>J. Gong</b> and T. Chen, <a href="https://arxiv.org/abs/2403.03322">Deep Configuration Performance Learning: A Systematic Survey and Taxonomy</a>, The ACM Transactions on Software Engineering and Methodology <a href="https://dl.acm.org/journal/tosem">(TOSEM)</a>, 2024, 62 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">SSBSE 2024</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">Challenge Winner</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CORE-B</span> <b>J. Gong</b>, S Li, G d'Aloisio, Z Ding, Y Ye, W Langdon and F Sarro, <a href="https://arxiv.org/abs/2407.14982">GreenStableYolo: Optimizing Inference Time and Image Quality of Text-to-Image Generation</a>, The Symposium on Search-Based Software Engineering Challenge Track <a href="https://conf.researchr.org/track/ssbse-2024/ssbse-2024-challenge">(SSBSE 2024)</a>, 6 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">FSE 2024</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-A</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CORE-A*</span> <b>J. Gong</b> and T. Chen, <a href="https://arxiv.org/abs/2402.03183">Predicting Configuration Performance in Multiple Environments with Sequential Meta-Learning</a>, The ACM International Conference on the Foundations of Software Engineering <a href="https://conf.researchr.org/home/fse-2024">(FSE 2024)</a>, 24 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">ESEC/FSE 2023</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-A</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CORE-A*</span> <b>J. Gong</b> and T. Chen, <a href="https://arxiv.org/pdf/2306.06651">Predicting Software Performance with Divide-and-Learn</a>, The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering <a href="https://2023.esec-fse.org/">(ESEC/FSE 2023)</a>, 13 pages. </div>

* <div style="text-align: justify"><span style="background-color:#5cb85c;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">MSR 2022</span> <span style="background-color:#e06666;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CCF-C</span> <span style="background-color:#0087BD;display: inline;padding: .2em .6em .3em;font-size: 75%;font-weight: bold;line-height: 1;color: #ffffff;text-align: center;white-space: nowrap;vertical-align: baseline;border-radius: .25em;">CORE-A</span> <b>J. Gong</b> and T. Chen, <a href="https://arxiv.org/abs/2203.15988">Does Configuration Encoding Matter in Learning Software Performance? An Empirical Study on Encoding Schemes</a>, The International Conference on Mining Software Repositories <a href="https://conf.researchr.org/details/msr-2022/msr-2022-technical-papers/1/Does-Configuration-Encoding-Matter-in-Learning-Software-Performance-An-Empirical-Stu">(MSR 2022)</a>, 13 pages. </div>


 

## Further Background
I received first-class BSc degree from both the [Information and Computing Science](https://www.xjtlu.edu.cn/en/study/undergraduate/information-and-computing-science)
programme at [Xi'an Jiaotong-Liverpool University](https://www.xjtlu.edu.cn/) (2014-16), and the [Computer Science](https://www.liverpool.ac.uk/courses/2024/computer-science-bsc-hons) 
course at [University of Liverpool](https://www.liverpool.ac.uk/) (2016-18). 